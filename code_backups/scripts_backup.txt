== Begin: gather_bug_information.sh.txt
import os
import json

def gather_bug_information(bug_name, output_directory):
    # Path to the bug list JSON file
    bug_list_path = "/Users/joshuaarnold/Documents/GitHub/Yean-Cat/bug_list.json"

    # Read the bug list
    with open(bug_list_path, 'r') as file:
        bug_list = json.load(file)

    # Find the bug in the bug list
    bug = next((bug for bug in bug_list if bug['name'] == bug_name), None)
    if not bug:
        print(f"Error: Bug '{bug_name}' not found in {bug_list_path}")
        return

    # Extract bug information
    bug_description = bug['description']
    related_objects = bug['related_objects']
    related_scripts = bug['related_scripts']
    related_logs = bug['related_logs']

    # Initialize the bug info text
    bug_info = f"Bug Name: {bug_name}\nDescription: {bug_description}\n\n"
    bug_info += "== Related Objects ==\n"

    object_dirs = [
        "/Users/joshuaarnold/Documents/GitHub/Yean-Cat/YEAN_CAT/objects",
        "/Users/joshuaarnold/Documents/GitHub/Yean-Cat/YEAN_CAT_SERVER/objects"
    ]

    for obj in related_objects:
        bug_info += f"\nObject: {obj}\n"
        for object_dir in object_dirs:
            obj_path = f"{object_dir}/{obj}"
            if os.path.exists(obj_path):
                for filename in os.listdir(obj_path):
                    if filename.endswith(".gml") or filename.endswith(".yy"):
                        file_path = os.path.join(obj_path, filename)
                        with open(file_path, 'r') as file:
                            code = file.read()
                        bug_info += f"\nFile: {filename}\nCode:\n{code}\n"
                break

    bug_info += "\n== Related Scripts ==\n"

    script_dirs = [
        "/Users/joshuaarnold/Documents/GitHub/Yean-Cat/YEAN_CAT/scripts",
        "/Users/joshuaarnold/Documents/GitHub/Yean-Cat/YEAN_CAT_SERVER/scripts"
    ]

    for script in related_scripts:
        for script_dir in script_dirs:
            script_path = f"{script_dir}/{script}.gml"
            if os.path.exists(script_path):
                with open(script_path, 'r') as file:
                    code = file.read()
                bug_info += f"\nScript: {script}\nCode:\n{code}\n"
                break

    bug_info += "\n== Related Logs ==\n"

    log_dirs = [
        "/Users/joshuaarnold/Documents/GitHub/Yean-Cat/GIT_GPT_SERVER/Logs/Client",
        "/Users/joshuaarnold/Documents/GitHub/Yean-Cat/GIT_GPT_SERVER/Logs/Server",
        "/Users/joshuaarnold/Documents/GitHub/Yean-Cat/GIT_GPT_SERVER/Logs/GIT_GPT"
    ]

    for log in related_logs:
        for log_dir in log_dirs:
            log_path = f"{log_dir}/{log}.txt"
            if os.path.exists(log_path):
                with open(log_path, 'r') as file:
                    log_content = file.read()
                bug_info += f"\nLog: {log}\nContent:\n{log_content}\n"
                break

    output_path = os.path.join(output_directory, f"bug_{bug_name}_information.txt")
    with open(output_path, 'w') as output_file:
        output_file.write(bug_info)

    print(f"Bug information saved to {output_path}")

# Example usage
if __name__ == "__main__":
    import sys
    if len(sys.argv) != 2:
        print("Usage: python gather_bug_information.sh <bug_name>")
    else:
        bug_name = sys.argv[1]
        output_directory = "/Users/joshuaarnold/Documents/GitHub/Yean-Cat/Bug_Info"
        gather_bug_information(bug_name, output_directory)

== End: gather_bug_information.sh.txt

== Begin: update_lists.sh.txt
#!/bin/bash

# Function to generate a list of scripts
generate_script_list() {
    local dir=$1
    local output_file=$2

    echo "Generating script list for $dir..."
    find "$dir" -name "*.gml" -exec basename {} .gml \; > "$output_file"
    echo "Script list generated at $output_file"
}

# Function to generate a list of commands
generate_command_list() {
    local dir=$1
    local output_file=$2

    echo "Generating command list for $dir..."
    grep -r "function scr_" "$dir" | awk -F'function scr_' '{print $2}' | awk -F'(' '{print $1}' | sort -u > "$output_file"
    echo "Command list generated at $output_file"
}

# Generate lists for client project
generate_script_list "YEAN_CAT/scripts" "script_list.txt"
generate_command_list "YEAN_CAT/scripts" "command_list.txt"

# Generate lists for server project
generate_script_list "YEAN_CAT_SERVER/scripts" "server_script_list.txt"
generate_command_list "YEAN_CAT_SERVER/scripts" "server_command_list.txt"

# Commit and push the updated lists
git add script_list.txt command_list.txt server_script_list.txt server_command_list.txt
git commit -m "Update script and command lists"

echo "Update completed successfully!"

== End: update_lists.sh.txt

== Begin: display_entry.sh.txt
#!/bin/bash

LIST_TYPE=$1  # Can be "bug", "planned_feature", "feature"
ENTRY_NAME=$2

if [ "$LIST_TYPE" == "bug" ]; then
    LIST_FILE="bug_list.json"
elif [ "$LIST_TYPE" == "planned_feature" ]; then
    LIST_FILE="planned_features.json"
elif [ "$LIST_TYPE" == "feature" ]; then
    LIST_FILE="completed_features.json"
else
    echo "Invalid list type specified."
    exit 1
fi

# Check if the list file exists
if [ ! -f "$LIST_FILE" ]; then
    echo "The list file $LIST_FILE does not exist."
    exit 1
fi

# Display the entry
jq --arg name "$ENTRY_NAME" '.[] | select(.name == $name)' "$LIST_FILE"

== End: display_entry.sh.txt

== Begin: generate_hierarchy.sh.txt
#!/bin/bash

# Create a hierarchies directory in the root
mkdir -p hierarchies

# Function to create a hierarchical representation of a directory
generate_hierarchy() {
    local directory=$1
    local output_file=$2
    local depth=$3

    echo "Generating hierarchy for $directory..."
    if [ -z "$depth" ]; then
        tree "$directory" -o "$output_file" || { echo "Failed to generate hierarchy for $directory"; exit 1; }
    else
        tree -L "$depth" "$directory" -o "$output_file" || { echo "Failed to generate hierarchy for $directory"; exit 1; }
    fi
    echo "Hierarchy generated at $output_file"
}

# Generate hierarchies for the required directories and save in the hierarchies folder
generate_hierarchy "GIT_GPT_SERVER" "hierarchies/GIT_GPT_SERVER_hierarchy.txt"
generate_hierarchy "YEAN_CAT" "hierarchies/YEAN_CAT_hierarchy.txt" 5
generate_hierarchy "YEAN_CAT_SERVER" "hierarchies/YEAN_CAT_SERVER_hierarchy.txt"

# Generate top-level hierarchy for Yean-Cat without including files within subdirectories
generate_hierarchy "." "hierarchies/Yean-Cat_hierarchy.txt" 1

echo "Hierarchy creation completed successfully!"

== End: generate_hierarchy.sh.txt

== Begin: deploy_all.sh.txt
#!/bin/bash

# Step 1: Set environment variables from .env
source .env

# Step 2: Update GitHub remote URL with token
echo "Updating GitHub remote URL..."
git remote set-url origin https://JayArnoldProd:${GITHUB_TOKEN}@github.com/JayArnoldProd/Yean-Cat.git

# Step 3: Run code_backup script with hierarchy generation
echo "Running backup script..."
./GIT_GPT_SERVER/scripts/code_backup.sh

# Step 4: Identify and kill specific Flask processes
echo "Checking for and killing existing Flask servers on ports 5000..."
./GIT_GPT_SERVER/scripts/stop_server.sh

# Step 5: Run force_push.sh with an optional commit message argument
echo "Running force_push.sh..."
./GIT_GPT_SERVER/scripts/force_push.sh "${1:-Catch up with local changes}"

# Step 6: Check if the server is running and pull logs
if curl -s --head http://localhost:5000 | grep "200 OK" > /dev/null; then
    echo "Pulling logs from the server..."
    curl -X POST http://localhost:5000/api/update_code/pull_logs -o Logs/server_logs.json
else
    echo "Server is not running. Starting the Flask server..."
    cd /Users/joshuaarnold/Documents/GitHub/Yean-Cat/GIT_GPT_SERVER
    export FLASK_APP=server.py
    flask run &
    FLASK_PID=$!  # Capture the Flask server PID
    echo $FLASK_PID > /Users/joshuaarnold/Documents/GitHub/Yean-Cat/GIT_GPT_SERVER/flask_pid.txt
    sleep 5  # Wait for the server to start
    echo "Pulling logs from the server..."
    curl -X POST http://localhost:5000/api/update_code/pull_logs -o Logs/server_logs.json
fi

echo "Backup and deployment completed successfully!"

# Step 7: Optionally run test API endpoints script
echo "Running test API endpoints script..."
if [ -f /Users/joshuaarnold/Documents/GitHub/Yean-Cat/GIT_GPT_SERVER/scripts/tests/test_api_endpoints.py ]; then
    python /Users/joshuaarnold/Documents/GitHub/Yean-Cat/GIT_GPT_SERVER/scripts/tests/test_api_endpoints.py
else
    echo "Test script not found."
fi

echo "Deployment and run completed successfully!"

== End: deploy_all.sh.txt

== Begin: search_entries.sh.txt
#!/bin/bash

LIST_TYPE=$1  # Can be "bug", "planned_feature", "feature"
SEARCH_FIELD=$2
SEARCH_VALUE=$3

if [ "$LIST_TYPE" == "bug" ]; then
    LIST_FILE="bug_list.json"
elif [ "$LIST_TYPE" == "planned_feature" ]; then
    LIST_FILE="planned_features.json"
elif [ "$LIST_TYPE" == "feature" ]; then
    LIST_FILE="completed_features.json"
else
    echo "Invalid list type specified."
    exit 1
fi

# Check if the list file exists
if [ ! -f "$LIST_FILE" ]; then
    echo "The list file $LIST_FILE does not exist."
    exit 1
fi

# Search for entries
jq --arg field "$SEARCH_FIELD" --arg value "$SEARCH_VALUE" \
   '.[] | select(.[$field] == $value)' "$LIST_FILE"

== End: search_entries.sh.txt

== Begin: ask_user.sh.txt
#!/bin/bash

QUESTION=$1
INPUT_TYPE=$2  # Can be "yesno" or "freeinput"

if [ "$INPUT_TYPE" == "yesno" ]; then
    while true; do
        read -p "$QUESTION (y/n): " yn
        case $yn in
            [Yy]* ) echo "yes"; break;;
            [Nn]* ) echo "no"; break;;
            * ) echo "Please answer yes or no.";;
        esac
    done
elif [ "$INPUT_TYPE" == "freeinput" ]; then
    read -p "$QUESTION: " input
    echo "$input"
else
    echo "Invalid input type specified."
fi

== End: ask_user.sh.txt

== Begin: add_bug.sh.txt
#!/bin/bash

BUG_NAME=$1
BUG_DESCRIPTION=$2
BUG_SOURCE=$3
BUG_PRIORITY=$4
BUG_STATUS=$5
BUG_DATE_REPORTED=$6
BUG_REPORTED_BY=$7
BUG_ASSIGNED_TO=$8
BUG_GENERATION=$9
BUG_LOGS=${10}
BUG_STEPS_TO_REPRODUCE=${11}
BUG_RESOLUTION=${12}
BUG_RELATED_FEATURES=${13}

jq --arg name "$BUG_NAME" --arg description "$BUG_DESCRIPTION" --arg source "$BUG_SOURCE" --arg priority "$BUG_PRIORITY" \
   --arg status "$BUG_STATUS" --arg date_reported "$BUG_DATE_REPORTED" --arg reported_by "$BUG_REPORTED_BY" \
   --arg assigned_to "$BUG_ASSIGNED_TO" --arg generation "$BUG_GENERATION" --arg logs "$BUG_LOGS" \
   --arg steps_to_reproduce "$BUG_STEPS_TO_REPRODUCE" --arg resolution "$BUG_RESOLUTION" --arg related_features "$BUG_RELATED_FEATURES" \
   '. += [{"name": $name, "description": $description, "source": $source, "priority": $priority, "status": $status, \
   "date_reported": $date_reported, "reported_by": $reported_by, "assigned_to": $assigned_to, "generation": $generation, \
   "logs": $logs, "steps_to_reproduce": $steps_to_reproduce, "resolution": $resolution, "related_features": $related_features}]' \
   bug_list.json > tmp.json && mv tmp.json bug_list.json

echo "Bug added successfully."

== End: add_bug.sh.txt

== Begin: add_feature.sh.txt
#!/bin/bash

FEATURE_NAME=$1
FEATURE_DESCRIPTION=$2
FEATURE_SOURCE=$3
FEATURE_PRIORITY=$4
FEATURE_STATUS=$5
FEATURE_DATE_COMPLETED=$6
FEATURE_IMPLEMENTED_BY=$7
FEATURE_GENERATION=$8
FEATURE_RELATED_BUGS=${9}
FEATURE_IMPLEMENTATION_STEPS=${10}
FEATURE_DEPENDENCIES=${11}
FEATURE_DOCUMENTATION=${12}

jq --arg name "$FEATURE_NAME" --arg description "$FEATURE_DESCRIPTION" --arg source "$FEATURE_SOURCE" --arg priority "$FEATURE_PRIORITY" \
   --arg status "$FEATURE_STATUS" --arg date_completed "$FEATURE_DATE_COMPLETED" --arg implemented_by "$FEATURE_IMPLEMENTED_BY" \
   --arg generation "$FEATURE_GENERATION" --arg related_bugs "$FEATURE_RELATED_BUGS" \
   --arg implementation_steps "$FEATURE_IMPLEMENTATION_STEPS" --arg dependencies "$FEATURE_DEPENDENCIES" \
   --arg documentation "$FEATURE_DOCUMENTATION"

== End: add_feature.sh.txt

== Begin: add_planned_feature.sh.txt
#!/bin/bash

FEATURE_NAME=$1
FEATURE_DESCRIPTION=$2
FEATURE_SOURCE=$3
FEATURE_PRIORITY=$4
FEATURE_STATUS=$5
FEATURE_DATE_PLANNED=$6
FEATURE_PLANNED_BY=$7
FEATURE_ASSIGNED_TO=$8
FEATURE_GENERATION=$9
FEATURE_RELATED_BUGS=${10}
FEATURE_IMPLEMENTATION_STEPS=${11}
FEATURE_DEPENDENCIES=${12}

jq --arg name "$FEATURE_NAME" --arg description "$FEATURE_DESCRIPTION" --arg source "$FEATURE_SOURCE" --arg priority "$FEATURE_PRIORITY" \
   --arg status "$FEATURE_STATUS" --arg date_planned "$FEATURE_DATE_PLANNED" --arg planned_by "$FEATURE_PLANNED_BY" \
   --arg assigned_to "$FEATURE_ASSIGNED_TO" --arg generation "$FEATURE_GENERATION" --arg related_bugs "$FEATURE_RELATED_BUGS" \
   --arg implementation_steps "$FEATURE_IMPLEMENTATION_STEPS" --arg dependencies "$FEATURE_DEPENDENCIES" \
   '. += [{"name": $name, "description": $description, "source": $source, "priority": $priority, "status": $status, \
   "date_planned": $date_planned, "planned_by": $planned_by, "assigned_to": $assigned_to, "generation": $generation, \
   "related_bugs": $related_bugs, "implementation_steps": $implementation_steps, "dependencies": $dependencies}]' \
   planned_features.json > tmp.json && mv tmp.json planned_features.json

echo "Planned feature added successfully."

== End: add_planned_feature.sh.txt

== Begin: test_api_endpoints.py.txt
import requests
import os

BASE_URL = "https://yean-cat-git-gpt-dd907a6ae83f.herokuapp.com"

def print_response(response):
    try:
        response.raise_for_status()  # Check if the request was successful
        print("Response JSON:", response.json())
    except requests.exceptions.HTTPError as http_err:
        print(f"HTTP error occurred: {http_err}")
        print("Response Content:", response.content)
    except requests.exceptions.JSONDecodeError:
        print("Response Content:", response.content)

def main():
    print("Starting Pinecone Initialization Test")
    response = requests.post(f"{BASE_URL}/api/query", json={
        "prompt_name": "test_prompt",
        "input_text": "Initialize Pinecone"
    })
    print("Pinecone Initialization Test:")
    print_response(response)

    print("Starting GPT Connection Test")
    response = requests.post(f"{BASE_URL}/api/generate_prompt", json={
        "save_name": "test_save",
        "input_text": "Test GPT connection"
    })
    print("GPT Connection Test:")
    print_response(response)

    print("Starting Update Code Test")
    response = requests.post(f"{BASE_URL}/api/update_code", json={
        "file_path": "test.py",
        "new_content": "print('Hello World')",
        "commit_message": "Test update"
    })
    print("Update Code Test:")
    print_response(response)

    print("Starting Assistant Test")
    response = requests.post(f"{BASE_URL}/api/assistant", json={
        "message": "Test assistant",
        "thread_id": "test_thread"
    }, headers={
        "Authorization": f"Bearer {os.getenv('ASSISTANT_API_KEY')}"
    })
    print("Assistant Test:")
    print_response(response)

    print("Starting Pull Logs Test")
    response = requests.post(f"{BASE_URL}/api/update_code/pull_logs")
    print("Pull Logs Test:")
    print_response(response)

if __name__ == "__main__":
    main()

== End: test_api_endpoints.py.txt

== Begin: stop_server.sh.txt
#!/bin/bash
# stop_server.sh

# Function to kill a process using a specific port
kill_process_on_port() {
    local port=$1
    echo "Checking for existing server on port $port..."
    PID=$(lsof -t -i:$port)
    if [ ! -z "$PID" ]; then
        echo "Killing process $PID using port $port..."
        kill -9 $PID
    else
        echo "No process using port $port."
    fi
}

# Kill servers on specified ports
kill_process_on_port 5000
kill_process_on_port 5001

# Optionally, kill the Flask server using the PID saved in flask_pid.txt
FLASK_PID_FILE="GIT_GPT_SERVER/flask_pid.txt"
if [ -f "$FLASK_PID_FILE" ]; then
    echo "Killing Flask server using PID from $FLASK_PID_FILE..."
    FLASK_PID=$(cat "$FLASK_PID_FILE")
    if [ ! -z "$FLASK_PID" ]; then
        kill -9 $FLASK_PID
        echo "Flask server with PID $FLASK_PID has been killed."
        rm "$FLASK_PID_FILE"
    else
        echo "No Flask server PID found in $FLASK_PID_FILE."
    fi
else
    echo "$FLASK_PID_FILE not found."
fi

echo "Server shutdown completed successfully!"

== End: stop_server.sh.txt

== Begin: update_entry.sh.txt
#!/bin/bash

LIST_TYPE=$1  # Can be "bug", "planned_feature", "feature"
ENTRY_NAME=$2
FIELD_NAME=$3
NEW_VALUE=$4

if [ "$LIST_TYPE" == "bug" ]; then
    LIST_FILE="bug_list.json"
elif [ "$LIST_TYPE" == "planned_feature" ]; then
    LIST_FILE="planned_features.json"
elif [ "$LIST_TYPE" == "feature" ]; then
    LIST_FILE="completed_features.json"
else
    echo "Invalid list type specified."
    exit 1
fi

# Check if the list file exists
if [ ! -f "$LIST_FILE" ]; then
    echo "The list file $LIST_FILE does not exist."
    exit 1
fi

# Check if an entry with the specified name exists
EXISTING_ENTRY=$(jq --arg name "$ENTRY_NAME" '.[] | select(.name == $name)' "$LIST_FILE")

if [ -z "$EXISTING_ENTRY" ]; then
    echo "No entry with the name '$ENTRY_NAME' found in $LIST_FILE."
    exit 1
fi

# Update the specified field
jq --arg name "$ENTRY_NAME" --arg field "$FIELD_NAME" --arg value "$NEW_VALUE" \
   '(.[] | select(.name == $name) | .[$field]) = $value' "$LIST_FILE" > tmp.json && mv tmp.json "$LIST_FILE"

echo "Entry '$ENTRY_NAME' updated successfully in $LIST_FILE."

== End: update_entry.sh.txt

== Begin: deploy.sh.txt
#!/bin/bash
# Navigate to the project directory
cd /Users/joshuaarnold/Documents/GitHub/Yean-Cat

# Push to Heroku
echo "Pushing to Heroku..."
git push heroku main

== End: deploy.sh.txt

== Begin: force_push.sh.txt
#!/bin/bash

# Get the commit message from the argument, default to a preset value if not provided
COMMIT_MESSAGE=${1:-"Catch up with local changes"}

# Navigate to the project directory
cd /Users/joshuaarnold/Documents/GitHub/Yean-Cat

# Set the GitHub remote URL with token
echo "Setting GitHub remote URL..."
git remote set-url origin https://JayArnoldProd:${GITHUB_TOKEN}@github.com/JayArnoldProd/Yean-Cat.git

# Add all changes
echo "Adding changes..."
git add .

# Commit with the provided message
echo "Committing changes..."
git commit -m "$COMMIT_MESSAGE"

# Force push to main
echo "Pushing to GitHub with force..."
git push origin main --force

echo "Force push completed successfully!"

== End: force_push.sh.txt

== Begin: complete_feature.sh.txt
#!/bin/bash

FEATURE_NAME=$1
COMPLETED_BY=$2
CURRENT_GEN=$(./GIT_GPT_SERVER/scripts/get_config.py CURRENT_GEN)
CURRENT_DATE=$(date '+%Y-%m-%d')

PLANNED_FEATURES_FILE="./planned_features.json"
COMPLETED_FEATURES_FILE="./completed_features.json"

# Check if completed_features.json exists, create if it doesn't
if [ ! -f $COMPLETED_FEATURES_FILE ]; then
    echo "[]" > $COMPLETED_FEATURES_FILE
fi

# Find the feature in planned_features.json
FEATURE=$(jq --arg name "$FEATURE_NAME" '.[] | select(.name == $name)' $PLANNED_FEATURES_FILE)

if [ "$FEATURE" == "" ]; then
    echo "No planned feature with the name '$FEATURE_NAME' found."
    exit 1
fi

# Update the status and completion details
UPDATED_FEATURE=$(echo "$FEATURE" | jq --arg date "$CURRENT_DATE" --arg gen "$CURRENT_GEN" --arg completed_by "$COMPLETED_BY" \
    '.status = "completed" | .date_completed = $date | .generation = $gen | .completed_by = $completed_by')

# Add to completed_features.json
jq --argjson feature "$UPDATED_FEATURE" '. += [$feature]' $COMPLETED_FEATURES_FILE > tmp.json && mv tmp.json $COMPLETED_FEATURES_FILE

# Remove from planned_features.json
jq --arg name "$FEATURE_NAME" 'del(.[] | select(.name == $name))' $PLANNED_FEATURES_FILE > tmp.json && mv tmp.json $PLANNED_FEATURES_FILE

echo "Feature '$FEATURE_NAME' completed and moved to $COMPLETED_FEATURES_FILE successfully."

== End: complete_feature.sh.txt

== Begin: get_config.py.txt
#!/usr/bin/env python3

import json
import os
import sys

# Locate the project root and config file
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
CONFIG_FILE = os.path.join(BASE_DIR, 'config', 'config.json')

# Load JSON configuration
with open(CONFIG_FILE, 'r') as f:
    config = json.load(f)

def get_config_value(key):
    if key in config:
        print(config[key])
    else:
        print(f"Unknown configuration key: {key}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: get_config.py <CONFIG_KEY>", file=sys.stderr)
        sys.exit(1)
    
    get_config_value(sys.argv[1])

== End: get_config.py.txt

== Begin: backup.sh.txt
#!/bin/bash

# Function to backup a directory with specific file patterns
backup_directory() {
    local source_dir=$1
    local backup_file=$2
    shift 2
    local patterns=("$@")

    # Clear the backup file before writing new data
    : > "$backup_file"

    echo "Backing up files from $source_dir to $backup_file..."
    for pattern in "${patterns[@]}"; do
        find "$source_dir" -type f -name "$pattern" | while read -r file; do
            echo "== Begin: ${file##*/}" >> "$backup_file"
            # Handle binary files properly to prevent corruption
            if [[ $file == *.pyc ]]; then
                xxd "$file" >> "$backup_file"
            else
                cat "$file" >> "$backup_file"
            fi
            echo -e "\n== End: ${file##*/}\n" >> "$backup_file"
        done
    done
    echo "Backup completed for $source_dir to $backup_file"
}

# Ensure the code_backups directory exists
mkdir -p code_backups

# List of directories to backup
backup_dirs=(
    "code_text/GIT_GPT_SERVER/scripts"
    "code_text/GIT_GPT_SERVER/Logs"
    "code_text/GIT_GPT_SERVER/routes"
    "code_text/GIT_GPT_SERVER/scripts/tests"
    "code_text/GIT_GPT_SERVER/utils"
    "code_text/GIT_GPT_SERVER/prompts"
)

# Backup each directory
for dir in "${backup_dirs[@]}"; do
    backup_file="code_backups/$(basename "$dir")_backup.txt"
    backup_directory "$dir" "$backup_file" "*.txt"
done

# Backup specific groups of files
backup_directory "Documentation" "code_backups/documentation_backup.txt" "*.txt"
backup_directory "Prompt_Assembly" "code_backups/documentation_backup.txt" "*.txt"
backup_directory "code_text" "code_backups/config_backup.txt" "config.py.txt" "pyproject.toml.txt" "requirements.txt.txt" "runtime.txt.txt"
backup_directory "code_text" "code_backups/metadata_backup.txt" "command_list.txt.txt" "planned_features.json.txt"

# Explicitly include specific files that may be missed
backup_directory "code_text" "code_backups/documentation_backup.txt" "Game_Command_Format_Documentation.txt.txt" "Terminal_Commands_Documentation.txt.txt"

# Append Last_Words files to the documentation_backup.txt
LAST_WORDS_DIR="Last_Words"
documentation_backup="code_backups/documentation_backup.txt"

if [ -d "$LAST_WORDS_DIR" ]; then
    echo "Appending Last_Words files to $documentation_backup..."
    for file in "$LAST_WORDS_DIR"/*.txt; do
        [ -e "$file" ] || continue
        echo "== Begin: ${file##*/}" >> "$documentation_backup"
        cat "$file" >> "$documentation_backup"
        echo -e "\n== End: ${file##*/}\n" >> "$documentation_backup"
    done
    echo "Last_Words files appended to $documentation_backup"
else
    echo "Last_Words directory does not exist. Skipping."
fi

# Convert README.md to plain text and append to documentation_backup.txt
if [ -f "Documentation/README.md" ]; then
    echo "Converting README.md to plain text and appending to documentation_backup.txt..."
    pandoc "Documentation/README.md" -t plain -o "Documentation/README.txt"
    echo "== Begin: README.txt" >> "$documentation_backup"
    cat "Documentation/README.txt" >> "$documentation_backup"
    echo -e "\n== End: README.txt\n" >> "$documentation_backup"
    rm "Documentation/README.txt"
else
    echo "README.md does not exist. Skipping."
fi

# Debugging: Check if the specific files exist in the code_text directory
echo "Checking for specific files in the code_text directory..."
if [ -f "code_text/Game_Command_Format_Documentation.txt.txt" ]; then
    echo "Game_Command_Format_Documentation.txt.txt exists."
else
    echo "Game_Command_Format_Documentation.txt.txt does not exist."
fi

if [ -f "code_text/Terminal_Commands_Documentation.txt.txt" ]; then
    echo "Terminal_Commands_Documentation.txt.txt exists."
else
    echo "Terminal_Commands_Documentation.txt.txt does not exist."
fi

echo "Ensuring all files in code_text have the correct extensions..."
echo "Backup script completed successfully!"

== End: backup.sh.txt

== Begin: backup_config.sh.txt
#!/bin/bash

# Define directories and files to be backed up
directories=(
    "GIT_GPT_SERVER/scripts"
    "GIT_GPT_SERVER/Logs"
    "GIT_GPT_SERVER/.github"
    "GIT_GPT_SERVER/routes"
    "GIT_GPT_SERVER/tests"
    "GIT_GPT_SERVER/utils"
    "GIT_GPT_SERVER/prompts"
)

# Logical groups for miscellaneous files
group1=("Documentation/README.md" "Prompt_Assembly/intro.txt" "Documentation/Game_Command_Format_Documentation.txt")
group2=("GIT_GPT_SERVER/__init__.py" "GIT_GPT_SERVER/config/config.py" "GIT_GPT_SERVER/config/config.json" "GIT_GPT_SERVER/flask_pid.txt" "GIT_GPT_SERVER/server.py")
group3=("Documentation/Terminal_Commands_Documentation.txt" "command_list.txt" "server_script_list.txt" "server_command_list.txt")
group4=("bug_list.json" "planned_features.json" "package.json" "requirements.txt" "pyproject.toml")
group5=(".gitignore" ".gitattributes" ".slugignore" ".env" "Procfile")

== End: backup_config.sh.txt

== Begin: backup_code_text.sh.txt
#!/bin/bash

# Create the code_text directory in the root
mkdir -p code_text/GIT_GPT_SERVER/github/workflows

# Function to copy and rename files with .txt extension
copy_and_rename() {
    local src_file=$1
    local dest_file=$2
    cp "$src_file" "${dest_file}.txt"
    echo "Copied and renamed $src_file to ${dest_file}.txt"
}

# Recursive function to copy and rename files in directories
copy_dir_and_rename() {
    local src_dir=$1
    local dest_dir=$2

    mkdir -p "$dest_dir"
    for file in "$src_dir"/*; do
        if [ -d "$file" ]; then
            local sub_dir=$(basename "$file")
            if [[ "$sub_dir" == .* || "$sub_dir" == __pycache__ ]]; then
                continue
            fi
            copy_dir_and_rename "$file" "$dest_dir/$sub_dir"
        else
            filename=$(basename "$file")
            if [[ "$filename" == "__init__.py" ]]; then
                continue
            fi
            extension="${file##*.}"
            base="${file%.*}"
            copy_and_rename "$file" "$dest_dir/$(basename "$base").$extension"
        fi
    done
}

# Copy files to the code_text directory and rename with .txt extension
echo "Copying and converting files to code_text directory..."
copy_and_rename README.md code_text/README.md
copy_and_rename command_list.txt code_text/command_list.txt
copy_and_rename config.py code_text/config.py
copy_and_rename flask_pid.txt code_text/flask_pid.txt
copy_and_rename intro.txt code_text/intro.txt
copy_and_rename package.json code_text/package.json
copy_and_rename planned_features.json code_text/planned_features.json
copy_and_rename pyproject.toml code_text/pyproject.toml
copy_and_rename requirements.txt code_text/requirements.txt
copy_and_rename runtime.txt code_text/runtime.txt
copy_and_rename script_list.txt code_text/script_list.txt
copy_and_rename server.py code_text/server.py
copy_and_rename server_command_list.txt code_text/server_command_list.txt
copy_and_rename server_script_list.txt code_text/server_script_list.txt
copy_and_rename "Documentation/Game_Command_Format_Documentation.txt" "code_text/Game_Command_Format_Documentation.txt"
copy_and_rename "Documentation/Terminal_Commands_Documentation.txt" "code_text/Terminal_Commands_Documentation.txt"

# Copy GIT_GPT_SERVER directory structure to code_text and rename with .txt extension
copy_dir_and_rename GIT_GPT_SERVER code_text/GIT_GPT_SERVER

# Copy .github/workflows/main.yml to code_text/GIT_GPT_SERVER/github/workflows
if [ -f ".github/workflows/main.yml" ]; then
    copy_and_rename ".github/workflows/main.yml" "code_text/GIT_GPT_SERVER/github/workflows/main.yml"
else
    echo "File .github/workflows/main.yml does not exist"
fi

# Copy .gitignore, .slugignore, and .gitattributes to code_text
if [ -f ".gitignore" ]; then
    copy_and_rename ".gitignore" "code_text/gitignore"
else
    echo "File .gitignore does not exist"
fi

if [ -f ".slugignore" ]; then
    copy_and_rename ".slugignore" "code_text/slugignore"
else
    echo "File .slugignore does not exist"
fi

if [ -f ".gitattributes" ]; then
    copy_and_rename ".gitattributes" "code_text/gitattributes"
else
    echo "File .gitattributes does not exist"
fi

echo "Code text backup completed successfully!"

== End: backup_code_text.sh.txt

== Begin: delete_entry.sh.txt
#!/bin/bash

LIST_TYPE=$1  # Can be "bug", "planned_feature", "feature"
ENTRY_NAME=$2

if [ "$LIST_TYPE" == "bug" ]; then
    LIST_FILE="bug_list.json"
elif [ "$LIST_TYPE" == "planned_feature" ]; then
    LIST_FILE="planned_features.json"
elif [ "$LIST_TYPE" == "feature" ]; then
    LIST_FILE="completed_features.json"
else
    echo "Invalid list type specified."
    exit 1
fi

# Check if the list file exists
if [ ! -f "$LIST_FILE" ]; then
    echo "The list file $LIST_FILE does not exist."
    exit 1
fi

# Check if an entry with the specified name exists
EXISTING_ENTRY=$(jq --arg name "$ENTRY_NAME" '.[] | select(.name == $name)' "$LIST_FILE")

if [ -z "$EXISTING_ENTRY" ]; then
    echo "No entry with the name '$ENTRY_NAME' found in $LIST_FILE."
    exit 1
fi

# Remove the existing entry
jq --arg name "$ENTRY_NAME" 'del(.[] | select(.name == $name))' "$LIST_FILE" > tmp.json && mv tmp.json "$LIST_FILE"

echo "Entry '$ENTRY_NAME' deleted successfully from $LIST_FILE."

== End: delete_entry.sh.txt

== Begin: print_env.py.txt
# print_env.py
from dotenv import load_dotenv
import os

load_dotenv()

print("GITHUB_API_URL:", os.getenv('GITHUB_API_URL'))
print("GITHUB_TOKEN:", os.getenv('GITHUB_TOKEN'))
print("ASSISTANT_ID:", os.getenv('ASSISTANT_ID'))  # Ensure this is correctly named in Heroku
print("PINECONE_API_KEY:", os.getenv('PINECONE_API_KEY'))
print("PINECONE_INDEX_NAME:", os.getenv('PINECONE_INDEX_NAME'))
print("GITHUB_USERNAME:", os.getenv('GITHUB_USERNAME'))

== End: print_env.py.txt

== Begin: move_closed_bugs.sh.txt
#!/bin/bash

# Get the current generation
CURRENT_GEN=$(./GIT_GPT_SERVER/scripts/get_config.py CURRENT_GEN)
CURRENT_DATE=$(date '+%Y-%m-%d')

# Define paths
BUG_LIST_FILE="./bug_list.json"
FIXED_BUGS_FILE="./fixed_bugs.json"

# Check if fixed_bugs.json exists, create if it doesn't
if [ ! -f $FIXED_BUGS_FILE ]; then
    echo "[]" > $FIXED_BUGS_FILE
fi

# Extract closed bugs and remaining bugs
CLOSED_BUGS=$(jq 'map(select(.status == "closed"))' $BUG_LIST_FILE)
REMAINING_BUGS=$(jq 'map(select(.status != "closed"))' $BUG_LIST_FILE)

# Append closed bugs to fixed_bugs.json
if [ "$(echo $CLOSED_BUGS | jq 'length')" -gt 0 ]; then
    jq --argjson closed "$CLOSED_BUGS" '. + $closed' $FIXED_BUGS_FILE > tmp.json && mv tmp.json $FIXED_BUGS_FILE
fi

# Update bug_list.json with remaining bugs
echo "$REMAINING_BUGS" > $BUG_LIST_FILE

echo "Closed bugs moved to $FIXED_BUGS_FILE and removed from $BUG_LIST_FILE successfully."

== End: move_closed_bugs.sh.txt

== Begin: code_backup.sh.txt
#!/bin/bash

# Step 1: Run backup_code_text.sh
echo "Running backup_code_text.sh..."
./GIT_GPT_SERVER/scripts/backup_code_text.sh

# Step 2: Run backup.sh
echo "Running backup.sh..."
./GIT_GPT_SERVER/scripts/backup.sh

# Step 3: Run generate_hierarchy.sh
echo "Running generate_hierarchy.sh..."
./GIT_GPT_SERVER/scripts/generate_hierarchy.sh

echo "Code backup process completed successfully!"

== End: code_backup.sh.txt

== Begin: last_words.sh.txt
#!/bin/bash

# Check if the argument is provided
if [ -z "$1" ]; then
    echo "Error: No message provided."
    echo "Usage: ./GIT_GPT_SERVER/scripts/last_words.sh \"Your detailed monologue here.\""
    exit 1
fi

# Create the Last_Words directory if it doesn't exist
mkdir -p Last_Words

# Determine the next generation number
if [ -n "$(ls -A Last_Words)" ]; then
    last_number=$(ls Last_Words | grep -Eo '[0-9]+' | sort -n | tail -1)
    next_number=$((last_number + 1))
else
    next_number=1
fi

# Create the new last words file
last_words_file="Last_Words/last_words_generation_${next_number}.txt"
echo "$1" > "$last_words_file"

echo "Last words for generation ${next_number} saved to ${last_words_file}"

# Update the generation number in config.json
jq --argjson gen $next_number '.CURRENT_GEN = ($gen + 1)' GIT_GPT_SERVER/config/config.json > tmp.$$.json && mv tmp.$$.json GIT_GPT_SERVER/config/config.json

# Update the generation number in config.py
sed -i "" "s/CURRENT_GEN = .*/CURRENT_GEN = \"$((next_number + 1))\"/" GIT_GPT_SERVER/config/config.py

echo "Updated GIT_GPT_SERVER/config/config.json and GIT_GPT_SERVER/config/config.py to generation $((next_number + 1))"

== End: last_words.sh.txt

== Begin: add_entry.sh.txt
#!/bin/bash

TYPE=$1
shift

NAME=$1
DESCRIPTION=$2
SOURCE=$3
PRIORITY=$4
STATUS=$5
DATE=$6
REPORTED_BY=$7
ASSIGNED_TO=$8
GENERATION=$9
shift 9

# Remaining arguments
RELATED_LOGS=$1
STEPS=$2
EXPECTED_OUTCOME=$3
RELATED_FEATURES=$4
RELATED_OBJECTS=$5
RELATED_SCRIPTS=$6

# Function to convert a string to a JSON array
to_json_array() {
    local arr_str=$1
    echo "$arr_str" | tr -d '\n' | jq -R -s 'split(",") | map(select(length > 0))'
}

# Function to strip trailing spaces and newlines from the input strings
strip_trailing_newlines_and_spaces() {
    local input_str=$1
    echo "$input_str" | tr -d '\n' | sed 's/[[:space:]]*$//'
}

# Function to handle expected outcome specifically
strip_newlines_expected_outcome() {
    local input_str=$1
    echo "$input_str" | tr -d '\n' | sed 's/\\n/ /g'
}

# Convert string arrays to JSON arrays
RELATED_LOGS=$(strip_trailing_newlines_and_spaces "$RELATED_LOGS")
STEPS=$(strip_trailing_newlines_and_spaces "$STEPS")
EXPECTED_OUTCOME=$(strip_newlines_expected_outcome "$EXPECTED_OUTCOME")
RELATED_FEATURES=$(strip_trailing_newlines_and_spaces "$RELATED_FEATURES")
RELATED_OBJECTS=$(strip_trailing_newlines_and_spaces "$RELATED_OBJECTS")
RELATED_SCRIPTS=$(strip_trailing_newlines_and_spaces "$RELATED_SCRIPTS")

RELATED_LOGS=$(to_json_array "$RELATED_LOGS")
STEPS=$(to_json_array "$STEPS")
EXPECTED_OUTCOME=$(to_json_array "$EXPECTED_OUTCOME")
RELATED_FEATURES=$(to_json_array "$RELATED_FEATURES")
RELATED_OBJECTS=$(to_json_array "$RELATED_OBJECTS")
RELATED_SCRIPTS=$(to_json_array "$RELATED_SCRIPTS")

# File paths
BUG_LIST_FILE="./bug_list.json"
PLANNED_FEATURES_FILE="./planned_features.json"
FEATURES_FILE="./completed_features.json"
FIXED_BUGS_FILE="./fixed_bugs.json"

# Function to add an entry
add_entry() {
    local file=$1
    local entry=$2
    if [ ! -f $file ]; then
        echo "[]" > $file
    fi

    local existing_entry=$(jq --arg name "$NAME" '.[] | select(.name == $name)' $file)

    if [ "$existing_entry" != "" ]; then
        read -p "An entry with the name '$NAME' already exists. Do you want to replace it? (y/n): " replace
        if [ "$replace" != "y" ]; then
            echo "Entry addition canceled."
            exit 0
        fi
        jq --arg name "$NAME" 'del(.[] | select(.name == $name))' $file > tmp.json && mv tmp.json $file
    fi

    jq --argjson entry "$entry" '. += [$entry]' $file > tmp.json && mv tmp.json $file
    echo "Entry '$NAME' added successfully."
}

# Prepare entry JSON based on the type
case $TYPE in
    bug)
        ENTRY=$(jq -n --arg name "$NAME" --arg description "$DESCRIPTION" --arg source "$SOURCE" --arg priority "$PRIORITY" \
                    --arg status "$STATUS" --arg date_reported "$DATE" --arg reported_by "$REPORTED_BY" --arg assigned_to "$ASSIGNED_TO" \
                    --arg generation "$GENERATION" --argjson related_logs "$RELATED_LOGS" --argjson steps "$STEPS" --argjson resolution "$EXPECTED_OUTCOME" \
                    --argjson related_features "$RELATED_FEATURES" --argjson related_objects "$RELATED_OBJECTS" --argjson related_scripts "$RELATED_SCRIPTS" \
                    '{name: $name, description: $description, source: $source, priority: $priority, status: $status, date_reported: $date_reported, reported_by: $reported_by, assigned_to: $assigned_to, generation: $generation, related_logs: $related_logs, steps_to_reproduce: $steps, resolution: $resolution, related_features: $related_features, related_objects: $related_objects, related_scripts: $related_scripts}')
        add_entry $BUG_LIST_FILE "$ENTRY"
        ;;
    fixed_bug)
        ENTRY=$(jq -n --arg name "$NAME" --arg description "$DESCRIPTION" --arg source "$SOURCE" --arg priority "$PRIORITY" \
                    --arg status "$STATUS" --arg date_reported "$DATE" --arg reported_by "$REPORTED_BY" --arg assigned_to "$ASSIGNED_TO" \
                    --arg generation "$GENERATION" --argjson related_logs "$RELATED_LOGS" --argjson steps "$STEPS" --argjson resolution "$EXPECTED_OUTCOME" \
                    --argjson related_features "$RELATED_FEATURES" --argjson related_objects "$RELATED_OBJECTS" --argjson related_scripts "$RELATED_SCRIPTS" \
                    '{name: $name, description: $description, source: $source, priority: $priority, status: $status, date_reported: $date_reported, reported_by: $reported_by, assigned_to: $assigned_to, generation: $generation, related_logs: $related_logs, steps_to_reproduce: $steps, resolution: $resolution, related_features: $related_features, related_objects: $related_objects, related_scripts: $related_scripts}')
        add_entry $FIXED_BUGS_FILE "$ENTRY"
        ;;
    planned_feature)
        ENTRY=$(jq -n --arg name "$NAME" --arg description "$DESCRIPTION" --arg source "$SOURCE" --arg priority "$PRIORITY" \
                    --arg status "$STATUS" --arg date_planned "$DATE" --arg planned_by "$REPORTED_BY" --arg assigned_to "$ASSIGNED_TO" \
                    --arg generation "$GENERATION" --argjson related_logs "$RELATED_LOGS" --argjson implementation_steps "$STEPS" --argjson expected_outcome "$EXPECTED_OUTCOME" \
                    --argjson related_features "$RELATED_FEATURES" --argjson related_objects "$RELATED_OBJECTS" --argjson related_scripts "$RELATED_SCRIPTS" \
                    '{name: $name, description: $description, source: $source, priority: $priority, status: $status, date_planned: $date_planned, planned_by: $planned_by, assigned_to: $assigned_to, generation: $generation, related_logs: $related_logs, implementation_steps: $implementation_steps, expected_outcome: $expected_outcome, related_features: $related_features, related_objects: $related_objects, related_scripts: $related_scripts}')
        add_entry $PLANNED_FEATURES_FILE "$ENTRY"
        ;;
    feature)
        ENTRY=$(jq -n --arg name "$NAME" --arg description "$DESCRIPTION" --arg source "$SOURCE" --arg priority "$PRIORITY" \
                    --arg status "$STATUS" --arg date_completed "$DATE" --arg completed_by "$REPORTED_BY" --arg generation "$GENERATION" \
                    --argjson related_logs "$RELATED_LOGS" --argjson steps "$STEPS" --argjson expected_outcome "$EXPECTED_OUTCOME" --argjson documentation_links "$EXPECTED_OUTCOME" \
                    --argjson related_features "$RELATED_FEATURES" --argjson related_objects "$RELATED_OBJECTS" --argjson related_scripts "$RELATED_SCRIPTS" \
                    '{name: $name, description: $description, source: $source, priority: $priority, status: $status, date_completed: $date_completed, completed_by: $completed_by, generation: $generation, related_logs: $related_logs, implementation_steps: $steps, expected_outcome: $expected_outcome, documentation_links: $documentation_links, related_features: $related_features, related_objects: $related_objects, related_scripts: $related_scripts}')
        add_entry $FEATURES_FILE "$ENTRY"
        ;;
    *)
        echo "Invalid entry type. Use 'bug', 'fixed_bug', 'planned_feature', or 'feature'."
        exit 1
        ;;
esac

== End: add_entry.sh.txt

== Begin: move_completed_features.sh.txt
#!/bin/bash

# Get the current generation
CURRENT_GEN=$(./GIT_GPT_SERVER/scripts/get_config.py CURRENT_GEN)
CURRENT_DATE=$(date '+%Y-%m-%d')

# Define paths
PLANNED_FEATURES_FILE="./planned_features.json"
COMPLETED_FEATURES_FILE="./completed_features.json"

# Check if completed_features.json exists, create if it doesn't
if [ ! -f $COMPLETED_FEATURES_FILE ]; then
    echo "[]" > $COMPLETED_FEATURES_FILE
fi

# Extract completed features and remaining planned features
COMPLETED_FEATURES=$(jq 'map(select(.status == "completed"))' $PLANNED_FEATURES_FILE)
REMAINING_FEATURES=$(jq 'map(select(.status != "completed"))' $PLANNED_FEATURES_FILE)

# Append completed features to completed_features.json
if [ "$(echo $COMPLETED_FEATURES | jq 'length')" -gt 0 ]; then
    jq --argjson completed "$COMPLETED_FEATURES" '. + $completed' $COMPLETED_FEATURES_FILE > tmp.json && mv tmp.json $COMPLETED_FEATURES_FILE
fi

# Update planned_features.json with remaining planned features
echo "$REMAINING_FEATURES" > $PLANNED_FEATURES_FILE

echo "Completed features moved to $COMPLETED_FEATURES_FILE and removed from $PLANNED_FEATURES_FILE successfully."


== End: move_completed_features.sh.txt

== Begin: list_entries.sh.txt
#!/bin/bash

LIST_TYPE=$1  # Can be "bugs", "planned_features", "features", "fixed_bugs"
STATUS_FILTER=${2:-unresolved}  # Default to showing only unresolved bugs

BUG_LIST_FILE="./bug_list.json"
PLANNED_FEATURES_FILE="./planned_features.json"
FEATURES_FILE="./completed_features.json"
FIXED_BUGS_FILE="./fixed_bugs.json"

list_entries() {
    local file=$1
    if [ ! -f $file ]; then
        echo "[]"
    else
        cat $file
    fi
}

case $LIST_TYPE in
    bugs)
        if [ "$STATUS_FILTER" == "unresolved" ]; then
            list_entries $BUG_LIST_FILE | jq '.[] | select(.status != "closed")' | jq -s
        elif [ "$STATUS_FILTER" == "all" ]; then
            list_entries $BUG_LIST_FILE | jq '.'
        else
            echo "Invalid status filter specified. Use 'unresolved' or 'all'."
            exit 1
        fi
        ;;
    planned_features)
        list_entries $PLANNED_FEATURES_FILE | jq '.'
        ;;
    features)
        jq -s '.[0] + .[1]' <(list_entries $PLANNED_FEATURES_FILE) <(list_entries $FEATURES_FILE)
        ;;
    fixed_bugs)
        list_entries $FIXED_BUGS_FILE | jq '.'
        ;;
    *)
        echo "Invalid list type specified."
        exit 1
        ;;
esac

== End: list_entries.sh.txt

