########## Logs_backup.txt ##########
########## SessionLog_45453.16.txt ##########
06/09/24 22:53:39: Actions.txt not found. Starting with an empty actions map.
06/09/24 22:54:26: [Jay Arnold] Hello World!
06/09/24 22:54:37: [Jay Arnold] I will now demonstrate how the add action is not working
06/09/24 22:54:59: Action 'Lvl100' added successfully.
06/09/24 22:55:08: Executing action: level_up(100)
06/09/24 22:55:08: Level up initiated with goal: 100
06/09/24 22:55:18: [Jay Arnold] see? that works beautifully
06/09/24 22:55:22: Actions: Lvl100, 
06/09/24 22:55:37: [Jay Arnold] now what if i try /chat_bubble
06/09/24 22:55:50: Chat Bubble Created. Following 'yeancat' with text: 'Hello World!'
06/09/24 22:56:08: [Jay Arnold] the command works when executing normally, lets try and make it 
into an action
06/09/24 22:56:50: Action 'HelloWorld' added successfully.
06/09/24 22:56:54: Actions: Lvl100, HelloWorld, 
06/09/24 22:56:58: Actions saved successfully to Actions.txt.
06/09/24 22:57:15: [Jay Arnold] i will insert what the Actions.txt contains here:

Lvl100,level_up,[ 100 ]
HelloWorld,chat_bubble,[ ""Hello World!" ] // it appears to not have saved the second argument!

06/09/24 22:57:39: Executing action: chat_bubble("Hello World!)
06/09/24 22:57:39: Error: Owner object 'undefined' not found
06/09/24 22:57:52: [Jay Arnold] See! an error!
06/09/24 22:59:08: [Jay Arnold] I will now end the test. but first heres a list of all my commands i can
 use so far. We just need to fix this bug involving the actions and then
 we can make many cool systems that use our action system.
06/09/24 22:59:15: Commands: add_action(, chat_bubble(, disable_heartbeat, 
06/09/24 22:59:15: enable_heartbeat, execute_action(, game_end(, goto_planet(, 
06/09/24 22:59:15: jump_planet(, level_up(, list_actions, list_clients, list_commands, 
06/09/24 22:59:15: list_variables, return_controller, save_actions, save_game, 
06/09/24 22:59:15: save_macros, set_my_permission(, set_variable(, show_gamepad_mapping, 
06/09/24 22:59:15: show_lines(, show_variable(, show_wpm, toggle_debug, 
06/09/24 22:59:15: toggle_input_display, toggle_log_debug, toggle_server
06/09/24 22:59:30: Saved Game
06/09/24 22:59:30: Game saved and ending.






########## github_backup.txt ##########



########## prompts_backup.txt ##########
########## test_prompt.txt ##########
Introduction:
This prompt is designed to diagnose and provide a solution for a bug in the console of the Yean-Cat project.

Bug Description:
The console is experiencing a bug where it fails to execute certain commands correctly. Specifically, when the 'spawn_enemy' command is issued, the game does not spawn an enemy as expected. This issue occurs intermittently and seems to be related to the game's state or the sequence of previous commands.

Steps to Reproduce:
1. Start the game.
2. Open the console.
3. Enter the 'spawn_enemy' command.
4. Observe that no enemy is spawned, or an error message is displayed.

Relevant Scripts:
Script 1: console_command.gml

// Example script content for console_command.gml
if (command == "spawn_enemy") {
    if (game_state == "running") {
        instance_create_layer(x, y, "Enemies", obj_enemy);
    } else {
        show_debug_message("Cannot spawn enemy: Game is not in running state.");
    }
}

// Example script content for obj_enemy.gml
event_inherited();
hp = 100;
speed = 3;

// Example content for obj_console
if (keyboard_check_pressed(vk_enter)) {
    execute_console_command();
}
Logs:
No relevant logs for this bug.





########## routes_backup.txt ##########
########## assistant.py.txt ##########
from flask import Blueprint, request, jsonify
import requests
import os
import threading

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer {os.getenv("ASSISTANT_API_KEY")}'},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()
        
        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500



########## generate_prompt.py.txt ##########
from flask import Blueprint, request, jsonify
import json
import os

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name:
        return jsonify({"error": "Invalid input, 'save_name' field is required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}\n\n{item['description']}\n\n{format_description}\n\nAdditional Instructions: {additional_instructions}\n\n"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:\n{script_content}\n\n"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):\n{file_content}\n\n"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:\n" + "\n".join(log_contents) + "\n\n"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})



########## query.py.txt ##########
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone
import os

query_openai_route = Blueprint('query_openai_route', __name__)

index = init_pinecone_index(os.getenv('PINECONE_INDEX_NAME'))

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/api/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/api/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/api/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})



########## update_code.py.txt ##########
from flask import Blueprint, request, jsonify
import requests
import os

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500






########## tests_backup.txt ##########
########## test_api_endpoints.py.txt ##########
# tests/test_api_endpoints.py
import requests
import os

BASE_URL = "https://yean-cat-git-gpt-dd907a6ae83f.herokuapp.com"

# Function to print response content
def print_response(response):
    try:
        print("Response JSON:", response.json())
    except requests.exceptions.JSONDecodeError:
        print("Response Content:", response.content)

# Pinecone Initialization Test
response = requests.post(f"{BASE_URL}/api/query", json={
    "prompt_name": "test_prompt",
    "input_text": "Initialize Pinecone"
})
print("Pinecone Initialization Test:")
print_response(response)

# GPT Connection Test
response = requests.post(f"{BASE_URL}/api/generate_prompt", json={
    "save_name": "test_save",
    "input_text": "Test GPT connection"
})
print("GPT Connection Test:")
print_response(response)

# Update Code Test
response = requests.post(f"{BASE_URL}/api/update_code", json={
    "save_name": "test_save",
    "code_changes": [
        {
            "file_path": "test.py",
            "changes": "print('Hello World')"
        }
    ]
})
print("Update Code Test:")
print_response(response)

# Assistant Test
response = requests.post(f"{BASE_URL}/api/assistant", json={
    "query": "Test assistant",
    "context": "Testing the assistant endpoint."
}, headers={
    "Authorization": f"Bearer {os.getenv('ASSISTANT_API_KEY')}"
})
print("Assistant Test:")
print_response(response)






########## utils_backup.txt ##########
########## file_operations.py.txt ##########
def read_file(file_path):
    try:
        with open(file_path, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(file_path, content):
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    with open(file_path, 'w') as file:
        file.write(content)



########## openai_operations.py.txt ##########
import os
import requests

OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

def query_openai(prompt, model='gpt-4', retries=3):
    for i in range(retries):
        try:
            response = requests.post(
                'https://api.openai.com/v1/chat/completions',
                headers={'Authorization': f'Bearer {OPENAI_API_KEY}'},
                json={
                    'model': model,
                    'messages': [{'role': 'user', 'content': prompt}],
                    'max_tokens': 1000,
                    'temperature': 0.5,
                }
            )
            response.raise_for_status()
            return response.json()
        except requests.exceptions.HTTPError as e:
            if response.status_code == 429:  # Too Many Requests
                retry_after = int(response.headers.get("Retry-After", 10))  # default to 10 seconds
                time.sleep(retry_after + random.uniform(0, 1))  # adding some jitter
            else:
                raise e
    raise Exception("Max retries exceeded")



########## pinecone_operations.py.txt ##########
import os
from pinecone import Pinecone, ServerlessSpec

def init_pinecone_index():
    api_key = os.getenv('PINECONE_API_KEY')
    index_name = os.getenv('PINECONE_INDEX_NAME')

    if not api_key or not index_name:
        raise ValueError("PINECONE_API_KEY and PINECONE_INDEX_NAME must be set")

    pc = Pinecone(api_key=api_key)

    if index_name not in pc.list_indexes().names():
        pc.create_index(
            name=index_name,
            dimension=1536,
            metric="euclidean",
            spec=ServerlessSpec(
                cloud='aws',
                region='us-east-1'
            )
        )
    return pc.index(index_name)

def upsert_vectors_to_pinecone(vectors):
    index_name = os.getenv("PINECONE_INDEX_NAME")
    api_key = os.getenv("PINECONE_API_KEY")
    pc = Pinecone(api_key=api_key)
    index = pc.index(index_name)
    
    # Assuming vectors is a list of tuples (id, vector)
    index.upsert(vectors)






