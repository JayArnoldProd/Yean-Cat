
------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content,
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content.encode('utf-8').decode('ascii'),
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    if not os.path.exists(logs_dir):
        return jsonify({"error": "Logs directory does not exist."}), 404

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

# Ensure to register the blueprint in your main app file
# from your_blueprint_file import update_code_route
# app.register_blueprint(update_code_route)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content.encode('utf-8').decode('ascii'),
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    if not os.path.exists(logs_dir):
        return jsonify({"error": "Logs directory does not exist."}), 404

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

# Ensure to register the blueprint in your main app file
# from your_blueprint_file import update_code_route
# app.register_blueprint(update_code_route)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content.encode('utf-8').decode('ascii'),
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    if not os.path.exists(logs_dir):
        return jsonify({"error": "Logs directory does not exist."}), 404

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

# Ensure to register the blueprint in your main app file
# from your_blueprint_file import update_code_route
# app.register_blueprint(update_code_route)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content.encode('utf-8').decode('ascii'),
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    if not os.path.exists(logs_dir):
        return jsonify({"error": "Logs directory does not exist."}), 404

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)

# Ensure to register the blueprint in your main app file
# from your_blueprint_file import update_code_route
# app.register_blueprint(update_code_route)

------ GIT_GPT_SERVER/routes/assistant.py ------
from flask import Blueprint, request, jsonify
import threading
import requests
import os

assistant_route = Blueprint('assistant_route', __name__)

thread_lock = threading.Lock()
user_threads = {}

@assistant_route.route('/assistant', methods=['POST'])
def assistant():
    data = request.get_json()
    message = data.get('message')
    thread_id = data.get('thread_id', 'default')
    if not message:
        return jsonify({"error": "Invalid input, 'message' field is required"}), 400

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []

    try:
        response = requests.post(
            'https://api.openai.com/v1/assistants',
            headers={'Authorization': f'Bearer ' + os.getenv("ASSISTANT_API_KEY")},
            json={
                'message': message,
                'thread_id': thread_id,
                'context': user_threads[thread_id]
            }
        )
        response.raise_for_status()
        assistant_response = response.json()

        with thread_lock:
            user_threads[thread_id].append({"role": "assistant", "content": assistant_response['message']})

        return jsonify(assistant_response)
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

------ GIT_GPT_SERVER/routes/generate_prompt.py ------
from flask import Blueprint, jsonify, request
import os
import json
from threading import Lock

generate_prompt_route = Blueprint('generate_prompt_route', __name__)

thread_lock = Lock()
user_threads = {}

def read_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return file.read()
    except FileNotFoundError:
        return None

def write_file(filepath, content):
    with open(filepath, 'w') as file:
        file.write(content)

@generate_prompt_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    data = request.get_json()
    prompt_type = data.get('type')
    item_name = data.get('name')
    save_name = data.get('save_name')
    thread_id = data.get('thread_id', 'default')
    additional_instructions = data.get('additional_instructions', '')

    if not save_name or not thread_id:
        return jsonify({"error": "Invalid input, 'save_name' and 'thread_id' fields are required"}), 400

    intro = read_file('intro.txt')
    format_description = read_file('format_description.txt')

    if not intro or not format_description:
        return jsonify({"error": "Intro or format description files not found"}), 400

    try:
        if prompt_type == 'bug':
            with open('bug_list.json', 'r') as f:
                bug_list = json.load(f)
            item = next((bug for bug in bug_list if bug['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Bug not found"}), 400

        elif prompt_type == 'feature':
            with open('planned_features.json', 'r') as f:
                feature_list = json.load(f)
            item = next((feature for feature in feature_list if feature['name'] == item_name), None)
            if not item:
                return jsonify({"error": "Feature not found"}), 400

        else:
            return jsonify({"error": "Invalid prompt type"}), 400
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSON Decode Error: {e}"}), 500

    prompt = f"{intro}

{item['description']}

{format_description}

Additional Instructions: {additional_instructions}

"

    for script in item['related_scripts']:
        script_path = f"YEAN CAT/scripts/{script}/{script}.gml"
        script_content = read_file(script_path)
        if script_content:
            prompt += f"Script {script}:
{script_content}

"

    for obj in item['related_objects']:
        obj_path = f"YEAN CAT/objects/{obj}/"
        if os.path.isdir(obj_path):
            for filename in os.listdir(obj_path):
                if filename.endswith('.gml'):
                    file_content = read_file(os.path.join(obj_path, filename))
                    if file_content:
                        prompt += f"Object {obj} ({filename}):
{file_content}

"

    log_contents = []
    for log in item['logs']:
        log_content = read_file(f'Logs/{log}')
        if log_content:
            log_contents.append(log_content)
    prompt += "Logs:
" + "
".join(log_contents) + "

"

    prompt_file_path = f'prompts/{save_name}.txt'
    write_file(prompt_file_path, prompt)

    with thread_lock:
        if thread_id not in user_threads:
            user_threads[thread_id] = []
        user_threads[thread_id].append(prompt)

    return jsonify({"message": f"Prompt saved as '{prompt_file_path}'"})

------ GIT_GPT_SERVER/routes/query.py ------
from flask import Blueprint, jsonify
from utils.pinecone_operations import init_pinecone_index, upsert_vectors_to_pinecone

query_openai_route = Blueprint('query_openai_route', __name__)

index_name = "yean-cat-git-gpt-index"  # Use the correct index name
pinecone_instance = init_pinecone_index(index_name)
index = pinecone_instance.Index(index_name)

@query_openai_route.route('/query', methods=['POST'])
def query_openai():
    # Your endpoint logic here
    return jsonify({"message": "Pinecone index queried successfully"})

@query_openai_route.route('/generate_prompt', methods=['POST'])
def generate_prompt():
    # Your endpoint logic here
    return jsonify({"message": "GPT prompt generated successfully"})

@query_openai_route.route('/update_code', methods=['POST'])
def update_code():
    # Your endpoint logic here
    return jsonify({"message": "Code updated successfully"})

@query_openai_route.route('/assistant', methods=['POST'])
def assistant():
    # Your endpoint logic here
    return jsonify({"message": "Assistant query successful"})

------ GIT_GPT_SERVER/routes/update_code.py ------
from flask import Blueprint, jsonify, request
import os
import requests

update_code_route = Blueprint('update_code_route', __name__)

@update_code_route.route('/api/update_code', methods=['POST'])
def update_code():
    data = request.get_json()
    file_path = data.get('file_path')
    new_content = data.get('new_content')
    commit_message = data.get('commit_message')

    if not file_path or not new_content or not commit_message:
        return jsonify({"error": "Missing required fields"}), 400

    GITHUB_API_URL = os.getenv('GITHUB_API_URL')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')

    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
    }
    try:
        get_file_response = requests.get(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers)
        get_file_response.raise_for_status()
        file_sha = get_file_response.json().get('sha')

        update_data = {
            'message': commit_message,
            'content': new_content.encode('utf-8').decode('ascii'),
            'sha': file_sha,
        }
        update_response = requests.put(f'{GITHUB_API_URL}/contents/{file_path}', headers=headers, json=update_data)
        update_response.raise_for_status()
        return jsonify(update_response.json())
    except requests.exceptions.RequestException as e:
        return jsonify({"error": str(e)}), 500

@update_code_route.route('/api/update_code/pull_logs', methods=['POST'])
def pull_logs():
    logs_dir = 'Logs'
    logs = {}

    if not os.path.exists(logs_dir):
        return jsonify({"error": "Logs directory does not exist."}), 404

    for log_file in os.listdir(logs_dir):
        if log_file.endswith('.txt'):
            try:
                with open(os.path.join(logs_dir, log_file), 'r') as file:
                    logs[log_file] = file.read()
            except FileNotFoundError:
                logs[log_file] = "Log file not found."
            except Exception as e:
                logs[log_file] = str(e)

    return jsonify(logs)
